{
  "name": "Local Drive Q&A System",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "local-qa",
        "options": {
          "responseHeaders": {
            "entries": [
              {
                "name": "Access-Control-Allow-Origin",
                "value": "*"
              }
            ]
          }
        }
      },
      "id": "webhook",
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "position": [250, 300],
      "typeVersion": 1,
      "webhookId": "local-qa-webhook",
      "notes": "Receives questions via HTTP POST"
    },
    {
      "parameters": {
        "functionCode": "// Extract and validate question\nconst body = $input.item.json.body;\nconst question = body.question || body.query || body.q;\n\nif (!question || question.trim().length === 0) {\n  throw new Error('Question is required. Send JSON with \"question\" field.');\n}\n\n// Clean and prepare question\nconst cleanedQuestion = question.trim();\n\n// Query expansion for better retrieval\n// Add synonyms and related terms\nconst expandedQuery = cleanedQuestion\n  .toLowerCase()\n  .replace(/[^a-z0-9\\s]/g, ' ')\n  .trim();\n\n// Log for debugging\nconsole.log(`Original question: ${cleanedQuestion}`);\nconsole.log(`Expanded query: ${expandedQuery}`);\n\nreturn {\n  original_question: cleanedQuestion,\n  expanded_query: expandedQuery,\n  timestamp: new Date().toISOString(),\n  session_id: body.session_id || 'default',\n  max_results: body.max_results || 5\n};"
      },
      "id": "process-question",
      "name": "Process Question",
      "type": "n8n-nodes-base.function",
      "position": [450, 300],
      "typeVersion": 1,
      "notes": "Validates and processes the incoming question"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://localhost:11434/api/embeddings",
        "options": {
          "bodyContentType": "json",
          "timeout": 30000
        },
        "bodyParametersJson": "{\n  \"model\": \"nomic-embed-text\",\n  \"prompt\": \"={{$json.expanded_query}}\"\n}"
      },
      "id": "embed-question",
      "name": "Embed Question",
      "type": "n8n-nodes-base.httpRequest",
      "position": [650, 300],
      "typeVersion": 3,
      "notes": "Generates embedding for the question"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://localhost:8000/api/v1/collections/local_docs/query",
        "options": {
          "bodyContentType": "json",
          "timeout": 10000
        },
        "bodyParametersJson": "{\n  \"query_embeddings\": [{{$json.embedding}}],\n  \"n_results\": {{$json.max_results}},\n  \"include\": [\"documents\", \"metadatas\", \"distances\"]\n}"
      },
      "id": "search-chromadb",
      "name": "Search ChromaDB",
      "type": "n8n-nodes-base.httpRequest",
      "position": [850, 300],
      "typeVersion": 3,
      "notes": "Searches for relevant document chunks"
    },
    {
      "parameters": {
        "functionCode": "// Process search results and build context\nconst results = $input.item.json;\nconst question = $input.item.json.original_question;\n\n// Check if we have results\nif (!results.documents || !results.documents[0] || results.documents[0].length === 0) {\n  return {\n    context: 'No relevant documents found in the local drive.',\n    sources: [],\n    question: question,\n    has_results: false\n  };\n}\n\n// Extract results\nconst documents = results.documents[0];\nconst metadatas = results.metadatas[0];\nconst distances = results.distances[0];\n\n// Build context from top results\nlet context = '';\nconst sources = [];\nconst seen_files = new Set();\n\n// Relevance threshold (lower is better for cosine distance)\nconst RELEVANCE_THRESHOLD = 0.7;\n\nfor (let i = 0; i < documents.length; i++) {\n  // Only include relevant results\n  if (distances[i] <= RELEVANCE_THRESHOLD) {\n    const metadata = metadatas[i];\n    const document = documents[i];\n    \n    // Add to context\n    context += `[Source: ${metadata.source}]\\n${document}\\n\\n`;\n    \n    // Track unique sources\n    if (!seen_files.has(metadata.path)) {\n      seen_files.add(metadata.path);\n      sources.push({\n        file: metadata.source,\n        path: metadata.path,\n        modified: metadata.modified,\n        relevance: (1 - distances[i]).toFixed(3),\n        chunk_info: `Chunk ${metadata.chunk_index + 1}/${metadata.total_chunks}`\n      });\n    }\n  }\n}\n\n// If no documents met the threshold\nif (context === '') {\n  context = 'Found documents but none were sufficiently relevant to the question.';\n}\n\nconsole.log(`Found ${sources.length} relevant source files`);\n\nreturn {\n  context: context,\n  sources: sources,\n  question: question,\n  num_sources: sources.length,\n  has_results: true\n};"
      },
      "id": "build-context",
      "name": "Build Context",
      "type": "n8n-nodes-base.function",
      "position": [1050, 300],
      "typeVersion": 1,
      "notes": "Builds context from search results"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://localhost:11434/api/generate",
        "options": {
          "bodyContentType": "json",
          "timeout": 60000
        },
        "bodyParametersJson": "{\n  \"model\": \"llama3.2:3b\",\n  \"prompt\": \"You are a helpful assistant that answers questions about documents stored on the local G: drive. Use ONLY the provided context to answer questions. If the answer is not in the context, say 'I cannot find this information in the available documents.'\\n\\nContext from local documents:\\n{{$json.context}}\\n\\nQuestion: {{$json.question}}\\n\\nInstructions:\\n1. Answer based ONLY on the provided context\\n2. Be specific and mention which document you're referencing\\n3. If multiple documents contain relevant info, synthesize them\\n4. Keep answers clear and concise\\n5. If you're unsure or the context doesn't contain the answer, say so\\n\\nAnswer:\",\n  \"stream\": false,\n  \"options\": {\n    \"temperature\": 0.3,\n    \"top_p\": 0.9,\n    \"max_tokens\": 500\n  }\n}"
      },
      "id": "generate-answer",
      "name": "Generate Answer",
      "type": "n8n-nodes-base.httpRequest",
      "position": [1250, 300],
      "typeVersion": 3,
      "notes": "Generates answer using Llama 3.2"
    },
    {
      "parameters": {
        "functionCode": "// Format final response\nconst answer = $input.item.json.response;\nconst sources = $input.item.json.sources;\nconst question = $input.item.json.question;\nconst has_results = $input.item.json.has_results;\n\n// Build response object\nconst response = {\n  success: true,\n  question: question,\n  answer: answer || 'Unable to generate an answer.',\n  sources: sources.map(s => ({\n    document: s.file,\n    path: s.path,\n    relevance_score: `${(parseFloat(s.relevance) * 100).toFixed(1)}%`,\n    chunk_info: s.chunk_info,\n    last_modified: s.modified\n  })),\n  metadata: {\n    timestamp: new Date().toISOString(),\n    model: 'llama3.2:3b',\n    num_sources_used: sources.length,\n    has_results: has_results\n  }\n};\n\n// Add helpful message if no sources\nif (sources.length === 0) {\n  response.answer = 'I could not find any relevant documents in the indexed files to answer your question. The documents may not contain this information, or you might need to reindex the G: drive if new documents were added recently.';\n}\n\nreturn response;"
      },
      "id": "format-response",
      "name": "Format Response",
      "type": "n8n-nodes-base.function",
      "position": [1450, 300],
      "typeVersion": 1,
      "notes": "Formats the final response"
    },
    {
      "parameters": {
        "options": {}
      },
      "id": "webhook-response",
      "name": "Webhook Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "position": [1650, 300],
      "typeVersion": 1,
      "notes": "Sends response back to caller"
    }
  ],
  "connections": {
    "Webhook": {
      "main": [[{"node": "Process Question"}]]
    },
    "Process Question": {
      "main": [[{"node": "Embed Question"}]]
    },
    "Embed Question": {
      "main": [[{"node": "Search ChromaDB"}]]
    },
    "Search ChromaDB": {
      "main": [[{"node": "Build Context"}]]
    },
    "Build Context": {
      "main": [[{"node": "Generate Answer"}]]
    },
    "Generate Answer": {
      "main": [[{"node": "Format Response"}]]
    },
    "Format Response": {
      "main": [[{"node": "Webhook Response"}]]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "meta": {
    "templateId": "qa-system-local",
    "templateVersion": "1.0.0",
    "templateDescription": "Q&A system for locally indexed documents"
  }
}